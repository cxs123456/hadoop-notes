## 1. HDFS概述(HDFS是什么、应用场景)
### 1.HDFS是什么
	HDFS（Hadoop Distributed File System）是 Apache Hadoop 项目的一个子项目，Hadoop 非常适于存储大型数据 (比如 TB 和 PB), 其就是使用 HDFS 作为存储系统。
	HDFS 使用多台计算机存储文件, 并且提供统一的访问接口, 像是访问一个普通文件系统一样使用分布式文件系统
	HDFS 是分布式文件存储系统
	
### 2.HDFS应用场景
	**适合的应用场景 **
	- 存储非常大的文件：这里非常大指的是几百M、G、或者TB级别，需要高吞吐量，对延时没有要求
	- 采用流式的数据访问方式: 即一次写入、多次读取，数据集经常从数据源生成或者拷贝一次，然后在其上做很多分析工作，**支持1写多读**
	- 运行于商业硬件上: Hadoop不需要特别贵的机器，可运行于普通廉价机器，可以处节约成本
	- 需要高容错性
	- 为数据存储提供所需的扩展能力
	
	**不适合的场景 **
	1. 低延时的数据访问，对延时要求在毫秒级别的应用，不适合采用HDFS。HDFS是为高吞吐数据传输设计的,因此可能牺牲延时
	2. 大量小文件，文件的元数据保存在 NameNode的内存中， 整个文件系统的文件数量会受限于NameNode的内存大小。
	3. 多方读写，需要任意的文件修改 HDFS采用追加（append-only）的方式写入数据。不支持文件任意owset的修改。不支持多个写入器（writer），**不支持多写**
	
## 2.HDFS 的架构组件、组件关系、原理
	
	HDFS是一个 主/从（Mater/Slave）体系结构
	### 1.HDFS的4个组成，NameNode、 DataNode、Secondary NameNode 和 HDFS Client
	① NameNode(nn) : 集群当中的主节点，管理文件元数据(文件的大小，文件的位置，文件的权限)，以及每个文件的块列表和块所在的DataNode
	② DataNode(dn) : 集群当中的从节点，主要用于存储文件块数据，以及块数据的校验和
	③ Secondary NameNode(2nn) : 辅助 NameNode，分担其工作量，定期合并 fsimage 和 edits，并推送给NameNode，在紧急情况下，可辅助恢复 NameNode
	④ Client : 文件切分。文件上传 HDFS 的时候，Client 将文件切分成 一个一个的Block，然后进行存储。
		与 NameNode 交互，获取文件的位置信息。
		与 DataNode 交互，读取或者写入数据。
		Client 提供一些命令来管理 和访问HDFS，比如启动或者关闭HDFS
	
	### 2. NameNode和DataNode的作用
	**NameNode 作用 **
	1. 管理元数据信息，
	2. 文件操作，NameNode负责文件元数据的操作 DataNode负责处理文件内容的读写请求，数据流不经过NameNode，会询问它跟那个DataNode联系
	3. 副本，文件数据块到底存放到哪些DataNode上，是由NameNode决定的，NN根据全局情况做出放置副本的决定
	4. 心跳机制，接收DataNode心跳信息，10分钟后还接受到不到DN的心跳，那么NameNode认为DataNode已经宕机 ,这时候
		NN准备要把DN上的数据块进行重新的复制
	
	**DataNode 作用 **
	1. 数据块block的形式存储HDFS文件
	2. 响应HDFS 客户端读写请求
	3. 周期性向NameNode汇报心跳信息、数据块信息和缓存数据块信息
	
	### 3.HDFS的副本机制和机架感知
	所有的文件都是以 block 块的方式存放在 HDFS 文件系统当中，block 块作用如下：
	1. 一个文件有可能大于集群中任意一个磁盘，引入块机制,可以很好的解决这个问题
	2. 块作为文件存储的逻辑单位可以简化存储子系统
	3. 块非常适合用于数据备份进而提供数据容错能力
	
	Hadoop1 当中, 文件的 block 块默认大小是 64M, hadoop2 当中, 文件的 block 块大小默认是128M, block 块的大小可以通过 hdfs-site.xml 当中的配置文件进行指定
	机架感知：HDFS分布式文件系统的副本存放策略
	
	### 4. HDFS 文件写入过程**
	** 写入过程是按照文件的每个block上传的 **
	① Client 通过 RPC 与 NameNode 建立通讯，发起文件上传请求，NameNode检查是否可以上传
	② Client 请求第1个 block 应该传输到哪些 DataNode 服务器上
	③ NameNode 根据配置文件中指定的备份数量及机架感知原理进行文件分配, 返回可用的 DataNode 的地址列表如: A, B, C
	④ Client 请求 3 台 DataNode 中的1台 A 上传数据（本质上是一个 RPC 调用，建立 pipeline 管道）, A 收到请求会继续调用 B, 然后 B 调用 C, 
	将整个 pipeline 建立完成, 后逐级返回 client
	⑤ Client 开始往 A 上传第一个 block（先从磁盘读取数据放到一个本地内存缓存）, 以 packet 为单位（默认64K）, A 收到一个 packet 就会传给 B, 
	B 传给 C. A 每传一个 packet 会放入一个应答队列等待应答
	⑥ block被分割成一个个 packet 数据包在 pipeline 上依次传输, 在 pipeline 反方向上, 逐个发送 ack（命令正确应答）, 
	最终由 pipeline 中第1个 DataNode 节点 A 将 pipeline ack 发送给 Client
	⑦ 当第1个 block 传输完成之后, 再上传第2个 block，同样按以上的流程上传
	
	### 5. HDFS 文件读取过程**
	① Client 通过 RPC 与 NameNode 建立通讯，发起文件读请求，NameNode检查是否可以读取
	② NameNode返回文件的部分或者全部block 所在 DataNode 地址列表，NameNode 会对 DN 地址进行排序（有排序规则）
	③ Client 与每1个block所在主机 建立 pipeline 管道，并行的读取所有 block 信息，读取完一个 block 都会进行 checksum（校验和） 验证，
		如果读取 DataNode 时出现错误，客户端会通知 NameNode，然后再从下一个拥有该 block 副本的DataNode 继续读。
	④ 当读完列表的 block 后，若文件读取还没有结束，客户端会继续向NameNode 获取下一批的 block 列表。
	⑤ 最终读取来的所有的 block 会合并成一个完整的最终文件。
	
	### 6. FsImage 和 Edits 详解 
	**Hadoop 的集群当中, NameNode的所有元数据信息都保存在了 FsImage 与 Eidts 文件中 **
	元数据信息的存放目录配置在 hdfs-site.xml 中
	
	Edits 记录NameNode最近一段时间的操作日志
	fsimage 保存某个时间前NameNode管理下的所有 DataNode 文件及文件 block 及 block所在的 DataNode 的元数据信息
	
	**edits ** 
	1. edits 记录客户端最近一段时间的操作日志
	2. 客户端对 HDFS 的写操作首先被记录在 edits 文件中
	3. edits 修改时元数据也会更新
	
	**fsimage ** 
	1. NameNode 中关于元数据的镜像，一般称为检查点，fsimage 存放了一份比较完整的元数据信息
	2. fsimage 是 NameNode 的完整的镜像，如果每次都加载到内存生成树状拓扑结构，这是非常耗内存和CPU, 
	所以一般开始时对 NameNode 的操作都放在 edits 中
	3. fsimage 内容包含了 NameNode 管理下的所有 DataNode 文件及文件 block 及 block所在的 DataNode 的元数据信息
	4. 随着 edits 内容增大, 就需要在一定时间点与 fsimage 进行合并
	
	** 查看edits 和 fsimage中的文件信息 **
	```
	# 查看fsimage 命令[ hdfs oiv ], oiv直译open image view
	cd /export/servers/hadoop2.7.5/hadoopDatas/namenodeDatas
	hdfs oiv -i fsimage_0000000000000000864 -p XML -o hello.xml
	
	# 查看edits 命令[ hdfs oev ], oev直译open edits view
	cd /export/servers/hadoop2.7.5/hadoopDatas/namenodeDatas
	hdfs oev -i edits_0000000000000000865-0000000000000000866 -p XML -o myedit.xml
	```
	
	### 7.SecondaryNameNode 如何辅助管理 fsimage 与 edits 文件
	① SecondaryNameNode 请求 NameNode 停止使用 edits，NameNode暂时将新写操作放入一个新的文件中 edits.new
	② 从 NameNode 中获得 fsimage 和 edits(通过http方式)，将 fsimage 载入内存, 然后开始合并 editlog, 生成新的fsimage
	③ 将新的 fsimage 发回给 NameNode，NameNode 把原有的 fsimage 替换为新的 fsimage, 把 edits.new 变成 edits，同时会更新 fstime
	
	一般把 NameNode 和 SecondaryNameNode 放在不同的机器上
	
	
## 3.HDFS 的API使用

	### 1.hdfs的命令行使用
	```
	# ls 
	# 显示文件目录列表
	hdfs dfs -ls /
	# lsr 
	# 在整个目录下递归执行ls, 与UNIX中的ls-R类似
	hdfs dfs -lsr /
	# mkdir 创建目录
	# 格式 ： hdfs dfs [-p] -mkdir <paths>
	
	# put
	# 将1个或多个本地源文件拷贝到hdfs上目标文件系统中（<dst>对应的路径）
	# 格式：hdfs dfs -put <localsrc > ... <dst>
	hdfs dfs -put /rooot/a.txt /dir1
	
	# moveFromLocal 和put命令类似，但是源文件localsrc拷贝之后自身被删除
	# 格式：hdfs dfs -moveFromLocal <localsrc> <dst>
	
	# get
	# 将hdfs上文件拷贝到本地文件系统。
	# 格式：hdfs dfs -get [-ignorecrc ] [-crc] <src> <localdst>
	hdfs dfs -get /install.log /export/servers
	
	# mv
	# 将hdfs上的文件从原路径移动到目标路径
	hdfs dfs -mv /dir1/a.txt /dir2
	
	# rm
	# 删除参数指定的文件，参数可以有多个，此命令只删除文件和非空目录，-r删除空目录
	# 格式：hdfs dfs -rm [-r] [-skipTrash] URI [URL...]
	hdfs dfs -rm -r /dir1
	
	# cp 
	# 将hdfs文件拷贝到目标路径中
	# 格式：hdfs dfs -cp URI [URI ...] <dest>
	hdfs dfs -cp /dir1/a.txt /dir2/b.txt
	
	# cat
	# chmod
	# chown
	以上命令和Linux命令类似
	
	# appendToFile
	# 追加一个或者多个本地文件到hdfs指定文件中
	# 格式: hdfs dfs -appendToFile <localsrc> ... <dst>
	hdfs dfs -appendToFile a.xml b.xml /big.xml
	```
	
	### 2.hdfs高级使用命令
	**HDFS文件限额配置 **
	hdfs文件的限额配置允许我们以文件个数，或者文件大小来限制我们在某个目录下上传的文件数量或者文件内容总量，
	以便达到我们类似百度网盘网盘等限制每个用户允许上传的最大的文件的量。
	```
	# 查看目录配额信息
	hdfs dfs -count -q -h /user/root/dir1 #查看配额信息
	
	# 数量限额 setQuota
	#创建hdfs文件夹
	hdfs dfs -mkdir -p /user/root/dir  
	# 给该文件夹下面设置最多上传两个文件，发现只能上传一个文件
	hdfs dfsadmin -setQuota 2 dir  
	# 清除文件数量限额 clrQuota
	hdfs dfsadmin -clrQuota /user/root/dir  
	
	# 空间限额 setSpaceQuota
	hdfs dfsadmin -setSpaceQuota 4k /user/root/dir # 限制空间大小4KB
	hdfs dfs -put /root/a.txt /user/root/dir
	# 清除空间配额限制 clrSpaceQuota
	hdfs dfsadmin -clrSpaceQuota /user/root/dir
	```
	
	### 3.HDFS安全模式
	安全模式是hadoop的一种保护机制，用于保证集群中的数据块的安全性。
	当集群启动的时候，会首先进入安全模式。
	当系统处于安全模式时会检查数据块的完整性。
	安全模式操作命令：safemode
	```
	hdfs dfsadmin -safemode get #查看安全模式状态
	hdfs dfsadmin -safemode enter #进入安全模式
	hdfs dfsadmin -safemode leave #离开安全模式
	```
	
	### 4.HDFS基准测试
	实际生产环境当中，hadoop的环境搭建完成之后，第一件事情就是进行压力测试，测试我们
	的集群的读取和写入速度，测试我们的网络带宽是否足够等一些基准测试
	**4.1 测试写入速度 **
	**4.2 测试读取速度 **
	**4.3 查看测试结果 **
	以上测试方法查看讲义说明

## 4.HDFS 的 Java API操作（如何使用，参考工程代码和讲义）
	
	### 1.使用文件系统方式访问数据（掌握）
	**涉及的主要类Class: **
	1. Configuration  该类的对象封转了客户端或者服务器的配置
	2. FileSystem  文件系统对象, 可以用该对象的一些方法来对文件进行操作, 通过FileSystem 的静态方法 get 获得该对象
	
	### 2.获取 FileSystem 的几种方式
	```
	// 方式1
	@Test
	public void getFileSystem1() throws IOException {
		Configuration configuration = new Configuration();
		// 指定我们使用的文件系统类型:
		configuration.set("fs.defaultFS", "hdfs://node01:8020/");

		// 获取指定的文件系统
		FileSystem fileSystem = FileSystem.get(configuration);
	}
	
	// 方式2
	FileSystem fileSystem = FileSystem.get(new URI("hdfs://node01:8020"), new Configuration());
	
	// 方式3
	Configuration configuration = new Configuration();
    configuration.set("fs.defaultFS", "hdfs://node01:8020");
    FileSystem fileSystem = FileSystem.newInstance(configuration);
	
	// 方式4
	FileSystem fileSystem = FileSystem.newInstance(new URI("hdfs://node01:8020") ,new Configuration());
	```
	

## 5.HDFS的高可用机制和Hadoop的联邦机制(Federation)
	### 1.HDFS高可用机制
	HA集群中，两台独立的机器被配置为NameNode。在工作集群中，NameNode机器中的一个处于Active状态，另一个处于Standby状态。
	Active NameNode负责群集中的所有客户端操作，而Standby充当从服务器。Standby机器保持足够的状态以提供快速故障切换
	
	#### 1.1 组件介绍
	ZKFailoverController
	HealthMonitor
	ActiveStandbyElector
	
	### 2.Hadoop 的联邦机制
	单NameNode的架构使得HDFS在集群扩展性和性能上都有潜在的问题，当集群大到一定程度后，NameNode进程使用的内存可能会达到上百G，NameNode成为了性能的瓶颈。
	因而提出了namenode水平扩展方案-- Federation。
	
	Federation中文意思为联邦,联盟，是NameNode的Federation,也就是会有多个NameNode。
	多个NameNode的情况意味着有多个namespace(命名空间)，(区别于HA模式下的多NameNode，它们是拥有着同一个namespace)。
	
	### 2.Federation 架构设计
	**HDFS Federation是解决namenode内存瓶颈问题的水平横向扩展方案。 **
	Federation中文意思为联邦,联盟，是NameNode的Federation,也就是会有多个NameNode。
	1. 多个NN共用一个集群里的存储资源，每个NN都可以单独对外提供服务
	2. 每个NN都会定义一个存储池，有单独的id，每个DN都为所有存储池提供存储。
	3. DN会按照存储池id向其对应的NN汇报块信息，同时，DN会向所有NN汇报本地存储可用资源情况
	
	**HDFS Federation不足 **
	HDFS Federation并没有完全解决单点故障问题，只是解决了内存不足问题和水平扩展。
	所以一般集群规模真的很大的时候，会采用HA+Federation的部署方案。也就是每个联合的namenodes都有HA
	
----
**PS:hadoop fs,hadoop dfs以及hdfs dfs区别 **
	**hadoop fs**
	FS relates to a generic file system which can point to any file systems like local, HDFS etc. 
	So this can be used when you are dealing with different file systems such as Local FS, HFTP FS, S3 FS, and others
	意思是说该命令可以用于其他文件系统，不止是hdfs文件系统内，也就是说该命令的使用范围更广
	
	**hadoop dfs**
	专门针对hdfs分布式文件系统
	**hdfs dfs**
	和上面的命令作用相同，相比于上面的命令更为推荐，并且当使用hadoop dfs时内部会被转为hdfs dfs命令








