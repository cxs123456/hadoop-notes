## 1. MapReduce 介绍(MapReduce是什么)
	
	### 1.MapReduce是什么(分布式计算框架)
	MapReduce是一个分布式运算程序的编程框架，核心功能是将用户编写的业务逻辑代码和自
	带默认组件整合成一个完整的分布式运算程序，并发运行在Hadoop集群上。
	
	**MapReduce将计算过程分为两个阶段：Map和Reduce **
	1）Map阶段并行处理输入数据
	2）Reduce阶段对Map结果进行汇总
	
	MapReduce中定义了如下的Map和Reduce两个抽象的编程接口，由用户去编程实现.Map和Reduce,MapReduce处理的数据类型是<key,value>键值对。
	- Map: (k1; v1) → [(k2; v2)]
	- Reduce: (k2; [v2]) → [(k3; v3)]
	
	一个完整的mapreduce程序在分布式运行时有三类实例进程：
	1. MRAppMaster 负责整个程序的过程调度及状态协调
	2. MapTask 负责map阶段的整个数据处理流程
	3. ReduceTask 负责reduce阶段的整个数据处理流程
	
	MapReduce运行在yarn集群
	1. ResourceManager
	2. NodeManager
	
## 2. MapReduce 编程规范
	**MapReduce 的开发有3个阶段8个步骤, 3个阶段分别是：Map、Shuffle、Reduce **
	**其中 Map 阶段 2 个步骤，Shuffle 阶段 4 个步骤，Reduce 阶段 2 个步骤 **
	
	### 1. Map 阶段 2 个步骤
	1. 设置 InputFormat 类, 将数据切分为 Key-Value(K1和V1) , 输入到第二步
	2. 自定义 Map 逻辑, 将第一步的结果转换成另外的 Key-Value（K2和V2）, 输出结果
	
	### 2. Shuffle 阶段 4 个步骤（分区、排序、规约、分组）
	3. 对输出的 Key-Value（K2和V2）对进行分区
	4. 对不同分区的数据按照相同的 Key 排序
	5. (可选) 对分组过的数据初步规约, 降低数据的网络拷贝
	6. 对数据进行分组, 相同 Key 的 Value 放入一个集合中
	
	### 3. Reduce 阶段 2 个步骤
	7. 自定义 Reduce 逻辑, 对输入的Key-Value（K2和V2）进行处理, 转为新的 Key-Value（K3和V3）输出
	8. 设置 OutputFormat类，处理并保存 Reduce 输出的 Key-Value 数据
	
	### 4.WordCount实现
	**需求: 在一堆给定的文本文件中统计输出每一个单词出现的总次数 **
	(参考工程代码和讲义，看懂代码和思想)
	

	```
	// 1.Mapper类
	public class WordCountMapper extends Mapper<LongWritable,Text,Text,LongWritable> {
		@Override
		public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
			String line = value.toString();
			String[] split = line.split(",");
			for (String word : split) {
				context.write(new Text(word),new LongWritable(1));
			}

		}
	}

	// 2.Reducer类
	public class WordCountReducer extends Reducer<Text,LongWritable,Text,LongWritable> {
		/**
		 * 自定义我们的reduce逻辑
		 * 所有的key都是我们的单词，所有的values都是我们单词出现的次数
		 * @param key
		 * @param values
		 * @param context
		 * @throws IOException
		 * @throws InterruptedException
		 */
		@Override
		protected void reduce(Text key, Iterable<LongWritable> values, Context context) throws IOException, InterruptedException {
			long count = 0;
			for (LongWritable value : values) {
				count += value.get();
			}
			context.write(key,new LongWritable(count));
		}
	}

	// 3.定义主类, 描述 Job 并提交 Job
	public class JobMain extends Configured implements Tool {
		@Override
		public int run(String[] args) throws Exception {
			Job job = Job.getInstance(super.getConf(), JobMain.class.getSimpleName());
			// 打包到集群上面运行时候，必须要添加以下配置，指定程序的main函数
			job.setJarByClass(JobMain.class);
			// 第1步：读取输入文件解析成key，value对
			job.setInputFormatClass(TextInputFormat.class);
			TextInputFormat.addInputPath(job,new Path("hdfs://192.168.52.250:8020/wordcount"));

			// 第2步：设置我们的mapper类
			job.setMapperClass(WordCountMapper.class);
			// 设置我们map阶段完成之后的输出类型
			job.setMapOutputKeyClass(Text.class);
			job.setMapOutputValueClass(LongWritable.class);
			// 第3步，第4步，第5步，第6步，省略
			// 第7步：设置我们的reduce类
			job.setReducerClass(WordCountReducer.class);
			// 设置我们reduce阶段完成之后的输出类型
			job.setOutputKeyClass(Text.class);
			job.setOutputValueClass(LongWritable.class);
			// 第8步：设置输出类以及输出路径
			job.setOutputFormatClass(TextOutputFormat.class);
			TextOutputFormat.setOutputPath(job,new Path("hdfs://192.168.52.250:8020/wordcount_out"));
			boolean b = job.waitForCompletion(true);
			return b?0:1;
		}

		/**
		 * 程序main函数的入口类
		 * @param args
		 * @throws Exception
		 */
		public static void main(String[] args) throws Exception {
			Configuration configuration = new Configuration();
			Tool tool  =  new JobMain();
			int run = ToolRunner.run(configuration, tool, args);
			System.exit(run);
		}
	}
	```
	### 5.MapReduce 运行模式 
	**1.本地运行模式 **
	```
	configuration.set("mapreduce.framework.name","local");
	configuration.set(" yarn.resourcemanager.hostname","local");
	TextInputFormat.addInputPath(job,new Path("file:///F:\\wordcount\\input"));
	TextOutputFormat.setOutputPath(job,new Path("file:///F:\\wordcount\\output"));
	```
	**2.集群运行模式 **
	hadoop jar hadoop_hdfs_operate-1.0-SNAPSHOT.jar cn.itcast.hdfs.demo1.JobMain
	
	### 6.MapReduce 分区，Partitioner类
	**分区概述 **
	在 MapReduce 中, 通过指定分区, 会将同一个分区的数据发送到同一个 Reduce 当中进行处理
	`需求：将以下数据进行分开处理`
	```
	// 1.自定义 Partitioner 类
	/**
	* 这里的输入类型与我们map阶段的输出类型<K2,V2>相同
	*/
	public class MyPartitioner extends Partitioner<Text,LongWritable> {
		/**
		* 返回值表示我们的数据要去到哪个分区
		* 返回值只是一个分区的标记，标记所有相同的数据去到指定的分区
		*/
		@Override
		public int getPartition(Text text, LongWritable longWritable, int i) {
			if(text.toString().length() >=5 ){
				return 0;
			}else{
				return 1;
			}
		}
	}
	
	// 2.主类中设置分区类和ReduceTask个数
	/**
	 * 设置我们的分区类，以及我们的reducetask的个数，注意reduceTask的个数一定要与我们的
	 * 分区数保持一致
	 */
	job.setPartitionerClass(MyPartitioner.class);
	job.setNumReduceTasks(2);	
	```
	
	### 7.MapReduce 排序和序列化 ，WritableComparable接口
	序列化 (Serialization) 是指把结构化对象转化为字节流
	反序列化 (Deserialization) 是序列化的逆过程. 把字节流转为结构化对象
	Hadoop自己开发了一套序列化机制(Writable)
	Hadoop 定义了这样一个 Writable 接口. 一个类要支持可序列化只需实现这个接口即可
	Writable 有一个子接口是 WritableComparable, WritableComparable 是既可实现序列化, 也可以对key进行比较, 
	我们这里可以通过自定义 Key 实现 WritableComparable 来实现我们的排序功能
	
	### 8.MapReduce 规约Combiner ， Reducer类
	**combiner 和 reducer 的区别在于运行的位置：**
	Combiner 是在每一个 maptask 所在的节点运行
	Reducer 是接收全局所有 Mapper 的输出结果
	combiner 的意义就是对每一个 maptask 的输出进行局部汇总，以减小网络传输量
	
	实现步骤
	1. 自定义一个 combiner 继承 Reducer，重写 reduce 方法
	2. 在 job 中设置 job.setCombinerClass(CustomCombiner.class)
		
	### 8.MapReduce案例-流量统计
	(参考工程代码和讲义，看懂代码和思想)
	
	需求一: 统计求和
	需求二: 上行流量倒序排序（递减排序）
	需求三: 手机号码分区
	
## 3 .MapReduce 运行机制详解
	(MapReduce 运行机制详解 参考讲义图片，看懂思想和原理)
	
	### 1.MapTask 工作机制
	**详细步骤 **
	① 读取数据组件 InputFormat (默认 TextInputFormat) 会通过 getSplits 方法对输入目录中文件进行逻辑切片规划得
	到 block , 有多少个 block 就对应启动多少个 MapTask。
	② 将输入文件切分为 block 之后, 由 RecordReader 对象 (默认是LineRecordReader) 进行读取, 以 \n 作为分隔符, 
	读取一行数据, 返回 <K1,V1> . K1 表示每行偏移值, V1 表示这一行文本内容
	③ 返回 <K1,V1>之后 , 进入用户自己继承的 Mapper 类中，执行用户重写的 map 方法, RecordReader 读取一行这里调用一次
	④ Mapper 逻辑结束之后, 将 Mapper 的每条结果通过 context.write 进行collect数据收集. 在 collect 中, 会先对其进行分区处理，默认使用 HashPartitioner
	⑤ 接下来, 会将数据写入内存, 内存中这片区域叫做环形缓冲区, 缓冲区的作用是批量收集
	Mapper 结果, 减少磁盘 IO 的影响. 我们的 Key/Value 对以及 Partition 的结果都会被写入
	缓冲区. 当然, 写入之前，Key 与 Value 值都会被序列化成字节数组。
	⑥ 当溢写线程启动后, 需要对这 80MB 空间内的 Key 做排序 (Sort). 排序是 MapReduce 模型
	默认的行为, 这里的排序也是对序列化的字节做的排序
	⑦ 合并溢写文件
	
	### 2.ReduceTask 工作机制
	Reduce 大致分为 copy、sort、reduce 三个阶段
	**详细步骤 **
	① Copy阶段 ，简单地拉取数据。Reduce进程启动一些数据copy线程(Fetcher)，通过HTTP
	方式请求maptask获取属于自己的文件。
	② Merge阶段 。这里的merge如map端的merge动作，只是数组中存放的是不同map端
	copy来的数值。Copy过来的数据会先放入内存缓冲区中，这里的缓冲区大小要比map端
	的更为灵活。merge有三种形式：内存到内存；内存到磁盘；磁盘到磁盘。默认情况下第
	一种形式不启用。当内存中的数据量到达一定阈值，就启动内存到磁盘的merge。与map
	端类似，这也是溢写的过程，这个过程中如果你设置有Combiner，也是会启用的，然后
	在磁盘中生成了众多的溢写文件。第二种merge方式一直在运行，直到没有map端的数据
	时才结束，然后启动第三种磁盘到磁盘的merge方式生成最终的文件。
	③ 合并排序 。把分散的数据合并成一个大的数据后，还会再对合并后的数据排序。
	④ 对排序后的键值对调用reduce方法 ，键相等的键值对调用一次reduce方法，每次调用会
	产生零个或者多个键值对，最后把这些输出的键值对写入到HDFS文件中。
	
	
	### 3.Shuffle 过程
	Shuffle 是 Mapreduce 的核心，它分布在 Mapreduce 的 map 阶段和 reduce 阶段
	**详细步骤 **
	① Collect阶段 ：将 MapTask 的结果输出到默认大小为 100M 的环形缓冲区，保存的是
	key/value，Partition 分区信息等。
	② Spill阶段 ：当内存中的数据量达到一定的阀值的时候，就会将数据写入本地磁盘，
	在将数据写入磁盘之前需要对数据进行一次排序的操作，如果配置了 combiner，还会将
	有相同分区号和 key 的数据进行排序。
	③ Merge阶段 ：把所有溢出的临时文件进行一次合并操作，以确保一个 MapTask 最终只
	产生一个中间数据文件。
	④ Copy阶段 ：ReduceTask 启动 Fetcher 线程到已经完成 MapTask 的节点上复制一份属于
	自己的数据，这些数据默认会保存在内存的缓冲区中，当内存的缓冲区达到一定的阀值
	的时候，就会将数据写到磁盘之上。
	⑤ Merge阶段 ：在 ReduceTask 远程复制数据的同时，会在后台开启两个线程对内存到本
	地的数据文件进行合并操作。
	⑥ Sort阶段 ：在对数据进行合并的同时，会进行排序操作，由于 MapTask 阶段已经对数
	据进行了局部的排序，ReduceTask 只需保证 Copy 的数据的最终整体有效性即可。
	Shuwle 中的缓冲区大小会影响到 mapreduce 程序的执行效率，原则上说，缓冲区越大，
	磁盘io的次数越少，执行速度就越快
	缓冲区的大小可以通过参数调整, 参数：mapreduce.task.io.sort.mb 默认100M
	
	**规约之后的属于reduceTask，之前的都是mapTask**
	
	### 4.MapReduce案例
	实现 SQL 查询运算
	select a.id,a.date,b.name,b.category_id,b.price from t_order a left
	join t_product b on a.pid = b.id
	(参考工程代码和讲义，看懂代码和思想)
	**案例: Reduce 端实现 JOIN **
	**案例: Map端实现 JOIN **
	**案例:求共同好友 **
	
	### 5.自定义InputFormat合并小文件
	**实现步骤：**
	1. 自定义一个InputFormat
	2. 改写RecordReader，实现一次读取一个完整文件封装为KV
	3. 在输出时使用SequenceFileOutPutFormat输出合并文件
	
	### 6.自定义outputFormat
	**需求 **
		现在有一些订单的评论数据，需求，将订单的好评与差评进行区分开来，将最终的数据分开
	到不同的文件夹下面去，数据内容参见资料文件夹，其中数据第九个字段表示好评，中评，
	差评。0：好评，1：中评，2：差评
	
	**实现步骤：**
	1. 在mapreduce中访问外部资源
	2. 自定义outputformat，改写其中的recordwriter，改写具体输出数据的方法write()
	
	### 7.自定义分组求取topN
	分组是mapreduce当中reduce端的一个功能组件
	//设置分组
	job.setGroupingComparatorClass(OrderGroupComparator.class);


