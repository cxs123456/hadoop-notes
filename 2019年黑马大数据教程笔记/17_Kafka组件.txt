## 1.Kafka 介绍
	
	### 1.Kafka是什么，应用场景
	**Apache Kafka是一个分布式发布-订阅消息系统 **
	
	消息系统的分类：点对点、发布-订阅
	发布与订阅主要3大组件：
	1. 主题：一个消息的分类 
	2. 发布者：将消息通过主动推送的方式推送给消息系统；
	3. 订阅者：可以采用拉、推的方式从消息系统中获取数据
	
	**Kafka的特点：**
	可靠性：分布式的，分区，多副本和容错的。
	可扩展性：kafka消息传递系统轻松缩放，无需停机。
	耐用性：kafka使用分布式提交日志，这意味着消息会尽可能快速的保存在磁盘上，因此它是持久的。 
	性能：kafka对于发布和订阅消息都具有高吞吐量。即使存储了许多TB的消息，他也爆出稳定的性能。 
	kafka非常快：保证零停机和零数据丢失。
	
	**Kafka应用场景：**
	消息系统的应用场景：应用解耦、流量控制、日志处理、消息通讯
	Kafka常用场景：指标分析、日志聚合、流式处理
	
	### 2.Kafka 架构
	**1.Kafka四大核心： Producers API、Consumers API、Stream Processors API、Connectors API**
	①生产者API：发布一个或者多个kafka的主题（topics），push模式发布消息。
	②消费者API：订阅一个或者多个主题，并处理这些主题接收到的记录流，pull模式获取消息。
	③StreamsAPI：
		允许应用程序充当流处理器（stream processor），从一个或者多个主题获取输入流，
		并生产一个输出流到一个或 者多个主题，能够有效的变化输入流为输出流。
	④ConnectorAPI：
		允许构建和运行可重用的生产者或者消费者，能够把kafka主题连接到现有的应用程序或数据系统。
		例如：一个连接到关系数据库的连接器可能会获取每个表的变化。
	
	**2.Kafka架构说明 **
	一个典型的kafka集群中包含若干个Producer，若干个Broker，若干个Consumer，以及一个zookeeper集群；
	kafka通过zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行Rebalance（负载均衡）；
	Producer使用push模式将消息发布到Broker；
	Consumer使用pull模式从Broker中订阅并消费消息；
	**简洁说明：**
	kafka集群包含多个Producer，多个Consumer，多个Broker，1个zookeeper集群；
	
	### 3.Kafka术语
	Broker：服务实例，kafka集群中包含一个或者多个服务实例，这种服务实例被称为Broker。
	Topic：主题，消息的分类，kafka集群的消息都有一个类别，这个类别就叫做Topic。
	Partition：分区，每个Topic有一个或者多个Partition，是一个物理上的概念。
	Producer：生产者，负责发布消息到kafka的Broker中。
	Consumer：消费者，kafka中消费消息的客户端。
	Consumer Group：消费者组，每一个 Consumer 属于一个特定的Consumer Group（可以为每个Consumer指定 groupName）
	
	**1.kafka中分区的重要概念：分区数、副本数、偏移量 **
	分区数(Partitions)：
	  控制topic将分片成多少个log文件，可以显示指定，如果不指定则会使用 broker（server.properties）中的num.partitions配置的数量。
	  - 分区有编号，编号从0开始。
	  - 分区的数据是有序的。
	  - 分区在创建topic时配置。
	副本数(Partition Replication)：
	  创建topic时可以指定副本数，副本因子应该小于等于可用的broker数。
	  控制消息保存在几个broker（服务器）上，一般情况下等于broker的个数，创建主题时，副本因子应该小于等于可用的broker数。
	偏移量(Partition offset)：
	  任何发布到partition的消息都会被直接追加到log文件的尾部，每条消息在log文件中的位置称为offset（偏移量）。
	  offset是一个long类型数字，它唯一标识了一条消息，消费者通过（offset，partition，topic）跟踪记录。
	
	**2.kafka分区和消费组之间的关系 **
	同一个组中的消费者对于同一条消息只消费一次。
	消费组中消费者数量应该小于等于该主题下的分区数。
	总结：分区数越多，同一时间可以有越多的消费者来进行消费，消费数据的速度就会越快，提高消费的性能。
	
	
## 2.Kafka 安装
	
	### 1.kafka集群的搭建
	集群规划：准备三台机器 node01 node02 node03，每台机器都已经安装JDK、Zookeeper，再安装Broker。
	①下载并解压Kafka的安装包
	tar -zxvf kafka_2.11-0.10.0.0.tgz -C /export/servers/
	②修改配置文件，分发到其他机器
	```
	// 修改配置文件中几个重要配置项，并分发到其他机器，修改broker.id和host.name
	cd /export/servers/kafka_2.11-0.10.0.0/config
	vim server.properties
	
	broker.id=0
	log.dirs=/export/servers/kafka_2.11-0.10.0.0/logs
	zookeeper.connect=node01:2181,node02:2181,node03:2181
	delete.topic.enable=true
	host.name=node01
	
	cd /export/servers/
	scp -r kafka_2.11-0.10.0.0/ node02:$PWD
	scp -r kafka_2.11-0.10.0.0/ node03:$PWD
	```
	③启动Kafka
	```
	// 1.前台启动
	bin/kafka-server-start.sh config/server.properties
	// 2.后台启动
	nohup bin/kafka-server-start.sh config/server.properties 1>/dev/null 2>&1 &
	```
	④停止Kafka进程  bin/kafka-server-stop.sh
	⑤查看Kafka进程  jps
	

## 3.Kafka 使用
	
	### 1.Kafka的shell操作
	①创建Topic
	bin/kafka-topics.sh --create --zookeeper node01:2181 --replication-factor 2 -- partitions 3 --topic test
	②查看所有主题
	bin/kafka-topics.sh  --list --zookeeper node01:2181,node02:2181,node03:2181
	③生产者生产数据/消费者消费数据
	// 模拟生产者来生产数据/消费者消费数据
	bin/kafka-console-producer.sh --broker-list node01:9092,node02:9092,node03:9092 --topic test
	bin/kafka-console-consumer.sh --from-beginning --topic test  --zookeeper node01:2181,node02:2181,node03:2181
	④查看指定主题 describe
	bin/kafka-topics.sh --describe --zookeeper node01:2181 --topic test
	⑤修改 topic 属性
	``` shell
	// 1.增加topic分区数，主题test分区数修改为8
	bin/kafka-topics.sh --zookeeper node01:2181 --alter --topic test --partitions 8
	// 2.删除topic配置
	bin/kafka-topics.sh --zookeeper node01:2181 --alter --topic test --delete-config flush.messages
	// 3.删除topic
	// server.properties中配置：
	// delete.topic.enable=true
	// 然后执行以下命令进行删除topic
	kafka-topics.sh --zookeeper zkhost:port --delete --topic topicName
	```
	
	### 2.Kafka的Java API操作(详细参考讲义和代码工程)
	#### 2.1 生产者消费者案例
	**开发大致过程：**
	pom文件引入kafka-clients、kafka-streams依赖
	①创建生产者对象KafkaProducer，设置配置对象
	②生产者对象发送消息KafkaProducer.send(ProducerRecord)，生产者消息对象ProducerRecord指定主题
	③创建消费者对象KafkaConsumer，设置配置对象
	④消费者订阅主题kafkaConsumer.subscribe(Arrays.asList("order"))
	⑤消费者获取消息kafkaConsumer.poll(100)，消费者消息对象ConsumerRecord
	
	#### 2.2 Kafka Streams API开发
	需求：使用StreamAPI获取 test1 这个 topic 当中的数据，然后将数据全部转为大写，写入到 test2 这个topic当中去
	**开发大致过程：**
	①创建Kafka流处理对象KafkaStreams，通过KStreamBuilder对象和属性对象创建
	```
	kStreamBuilder.stream("test1").mapValues(line -> line.toString().toUpperCase()).to("test2");
    KafkaStreams streams = new KafkaStreams(builder, props);
    streams.start();
	```
	②生产者向test1主题中生产数据，消费者向test2主题中消费数据，验证结果
	
	### 3.Kafka的原理(原理详情参考讲义)
	**生产者是线程安全的，消费者不是线程安全的。**
	
	#### 3.1 生产者数据分发策略 
	数据分发：指的数据被分发到哪个分区partition
	**生产者数据分发策略有如下4种方式：**
	```
	// 1.可根据主题和内容发送，轮询的方式将数据均匀的发送到不同的分区里面去
	public ProducerRecord(String topic, V value)
	// 2.根据主题、key、内容发送，通过key.hashCode  % numPartitions来计算数据究竟会保存在哪一个分区里面
	public ProducerRecord(String topic, K key, V value)
	// 3.根据主题、分区、key、内容发送，指定了分区号，那么就会将数据直接写入到对应的分区里面去
	public ProducerRecord(String topic, Integer partition, K key, V value)
	//根据主题、分区、时间戳、key，内容发送
	public ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value)
	```
	#### 3.2 消息的消费分为两种方式
	自动提交offset值：
	  props.put("enable.auto.commit", "true"); 
	  props.put("auto.commit.interval.ms",  "1000");
	手动提交offset值：
	  props.put("enable.auto.commit",  "false");
	  // 手动提交offset值
	  consumer.commitSync();
	  
	#### 3.3 Kafka的 log 存储机制
	1) kafka中log日志目录及组成
	kafka在我们指定的log.dir目录下，会创建一些文件夹；名字是【主题名字-分区名】所组成的文件夹
	在【主题名字-分区名】的目录下，会有多成对文件存在，如下所示：
	// 索引文件 00000000000000000000.index
	// 日志内容 00000000000000000000.log
	多个成对文件成为Segment file
	在kafka的设计中，将offset值作为了文件名的一部分，索引和日志文件是成对存在
	
	2) kafka的offset查找过程（重点：参考讲义说明）
	index文件中每行存储的是 key-value 对(都是整数)，key是log文件的第几条消息(相对于第几行)，value是该条消息在全局partiton表示第几个消息
	index文件中并没有为log文件中的每条消息都建立索引，而是采用了稀疏存储的方式，每隔一定字节的数据建立一条索引
	
	3) kafka如何保证数据不丢失
	broker：使用partition的副本机制
	生产者：使用ack机制
	消费者：提交offset
	
	### 4.CAP理论以及kafka当中的CAP机制
	Consistency：一致性，读写请求都由leader上处理，需保证写数据之后，读的数据一致。
	Availability：可用性，保证响应服务不挂机，解决方式：集群
	Partition tolerance：分区容错性，每个子网络就叫做一个区，区之间通信可能失败。一般来说，分区容错无法避免、
	
	kafka满足的是CAP定律当中的CA，其中Partition  tolerance通过的是一定的机制尽量的保证分区容错性。
	1. kafka的一致性：
	  首先将数据写入到不同的分区里面去，每个分区又可能有好多个副本，数据首先写入到leader分区里面去，
	  读写的操作都是与leader主分区进行通信，保证了数据的一致性原则，也就是满足了Consistency原则。
	2. kafka的可用性：
	  kafka通过分区副本机制，来保证了kafka当中数据的可用性。
	但是也存在另外一个问题，就是副本分区当中的数据与leader主分区当中的数据存在差别的问题如何解决，这个就是Partition tolerance的问题。
	kafka为了解决Partition tolerance的问题，使用了ISR的同步策略，来尽最大可能减少Partition tolerance的问题

	###	5.kafka监控及运维工具kafka-eagle(如何安装使用参考讲义)



